{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ćwiczenia 6. Walidacja Krzyżowa\n",
    "\n",
    "## PyTorch na następne ćwiczenia.\n",
    "\n",
    "Proszę zainstalować pakiet [PyTorch](https://pytorch.org/) oraz torchvision na kolejne zajęcia. Jeśli używane, mając swoje środowisko aktywne użyć:\n",
    "\n",
    " * GPU: `conda install pytorch torchvision cudatoolkit=9.0 -c pytorch`\n",
    " * tylko CPU: `conda install pytorch torchvision cpuonly  -c pytorch`\n",
    "\n",
    "## Klasyfikacja\n",
    "\n",
    "Dzisiaj na zajęciach zajmiemy się problemem klasyfikacji. Podobnie do regresji liniowej jest to przykład uczenia nadzorowanego, ale zamiast przewidywać konkretną liczbę dla danej obserwacji, przewidujemy jego przynajeżność do jednej z *k* klas. Na tych zajęciach będziemy rozważać klasyfikacje binarną, czyli uczyć modele odpowiadające funkcji:\n",
    "\n",
    "$$ f(x) = y, \\quad y \\in \\{0,1\\} $$\n",
    "\n",
    "Poniżej ładowane są dane, do razu już podzielone na dwie części."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import get_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.1 (0.5 pkt.)\n",
    "\n",
    "Używając modelu [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) z pakietu sklearn uzyskać 100% dokładność (mierzoną miarą [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))na zbiorze treningowym. Państwa zadanie polega na dobraniu parametru `gamma`, dla ułatwienia proszę nie zmieniać pozostałych domyślnych parametrów. Zalecany przedział parametru `gamma` to wartości z przedziału [0, 1] w skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wpisanie czegokolwiek powyzej 1 daje dobry wynik'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n",
    "\"\"\"wpisanie czegokolwiek powyzej 1 daje dobry wynik\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = 1# ???\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "train_acc = svm.score(X_train, y_train)\n",
    "assert train_acc == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.2 (0.5 pkt.)\n",
    "Używając tej samej rodziny modeli znajdź tym razem taką wartość `gamma`, która daje najlepszy wynik na zbiorze **testowym**. Powinieneś(-aś) być w stanie osiągnąć wynik co najmniej `0.95` accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6223776223776224, 0.6153846153846154, 0.9090909090909091, 0.9300699300699301, 0.951048951048951, 0.965034965034965, 0.972027972027972, 0.951048951048951, 0.951048951048951, 0.951048951048951, 0.9440559440559441, 0.9370629370629371, 0.9370629370629371, 0.9090909090909091, 0.8811188811188811, 0.8181818181818182]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "gamma=[ np.exp(i) for i in range(10)] #gamma>1\n",
    "gamma2=[ np.exp(-i) for i in range(20)] #gamma <1\n",
    "gamma=gamma+gamma2\n",
    "svm_table = [ SVC(gamma=val) for val in gamma]\n",
    "for svm in svm_table : svm.fit(X_train, y_train)\n",
    "testy_acc=[]\n",
    "for svm in svm_table: testy_acc.append(svm.score(X_test, y_test))\n",
    "print( testy_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "#best_gamma = np.exp(-10) \n",
    "best_gamma=np.exp(-10)\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "print(test_acc)\n",
    "assert test_acc >= 0.95\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "**W poprzednim zadaniu zakładaliśmy, że podział na zbiór trenujący/testujący jest nam podany z góry, ale co jeśli go nie mamy?**\n",
    "\n",
    "Możemy oczywiście sami arbitralnie wybrać część datasetu i uznać ją za nasz zbiór testowy, ale to mogą się z tym wiązać dodatkowe problemy: co jeśli wybrany przez nas fragment jest akurat różny od reszty datasetu, lub odwrotnie?\n",
    "\n",
    "**Rozwiązanie:** Walidacja Krzyżowa.\n",
    "\n",
    "1. Podziel dataset na zadaną przez parametr `k` liczbę (prawie) równych grup.\n",
    "2. Dla każdego podziału, zwróć jedną z tych części jako zbiór testowy, a sumę reszty jako zbiór treningowy.\n",
    "3. Po nauczeniu łącznie `k` modeli, uśrednij ich wyniki na zbiorach testowych i zwróć jako ostateczny wynik.\n",
    "\n",
    "## Zadanie 2. (2 pkt.)\n",
    "\n",
    "Państwa zadaniem jest zaimplementowanie walidacji krzyżowej, czyli funkcji, która dla podanego datasetu w postaci macierzy danych `X` i wektora etykiet `y` zwróci listę `k` krotek: \n",
    "  \n",
    "  `(treningowe_dane, treningowe_etykiety, testowe_dane, testowe_etykiety)`\n",
    "  \n",
    "podziałów dokonanych przez walidację krzyżową. Następnie należy użyć modelu z poprzedniego zadania dla policzenia dokładności na zbiorze testowym dla walidacji krzyżowej.\n",
    "\n",
    "Proszę **nie** korzystać z gotowych rozwiązań dostępnych w pakiecie sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def cross_validation(X: np.ndarray, y: np.ndarray, k: int) -> List[Tuple[np.ndarray, np.ndarray, \n",
    "                                                                         np.ndarray, np.ndarray]]:\n",
    "    p=np.random.permutation(X.shape[0])\n",
    "    X=X[p]\n",
    "    y=y[p]\n",
    "    step=int(X.shape[0]/k)\n",
    "    ret_list=[]\n",
    "    for i in range(k-1):\n",
    "        a=np.concatenate((X[:i*step],X[(i+1)*step:]))\n",
    "        b=np.concatenate((y[:i*step],y[(i+1)*step:]))\n",
    "        c=X[i*step:(i+1)*step]\n",
    "        d=y[i*step:(i+1)*step]\n",
    "        ret_list.append((a,b,c,d))\n",
    "    ret_list.append((X[:(k-1)*step],y[:(k-1)*step],X[(k-1)*step:],y[(k-1)*step:]))   \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import test_cv\n",
    "\n",
    "test_cv(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9312154905075258\n"
     ]
    }
   ],
   "source": [
    "X, y = get_data(split=False)\n",
    "def accuracy(X,y,k=5,gamma=1,C=1):\n",
    "    dane=cross_validation(X,y,k)\n",
    "    svm=SVC(gamma=gamma,C=C)\n",
    "    acc=0\n",
    "    for a,b,c,d in dane:\n",
    "        svm.fit(a,b)\n",
    "        #print(svm.score(c,d))\n",
    "        acc=acc+svm.score(c,d)\n",
    "\n",
    "    cv_accuracy = acc/k\n",
    "    return cv_accuracy\n",
    "print(accuracy(X,y,5,gamma=np.exp(-10),C=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (1 pkt.)\n",
    "\n",
    "Mając już lepszą metodę walidacji naszego rozwiązania Państwa zadaniem jest znalezienia najlepszego zestawu hiperparametrów dla modelu z poprzednich zadań, lecz tym razem będziemy szukać również parametru `C`. Parametru C zaleca się szukać w przedziale $(0, + \\infty)$ również w skali logarytmicznej.\n",
    "\n",
    "W zadaniu należy oczywiście skorzystać z zaimplementowanej przez Państwa walidacji krzyżowej. Ponieważ dla dwóch parametrów `C` oraz `gamma` możliwych kombinacji do przetestowania robi są dość sporo dla przetestowania dużych zakresów zalecane są również inne metody przeszukiwania, takie jak:\n",
    "\n",
    "* przeszukiwanie po kolei z jednym z parametrów ustalonym na stałą.\n",
    "* przeszukiwanie losowe obu parametrów\n",
    "\n",
    "Oczywiście jeśli zasoby na to pozwalają można szukać tzw. \"grid searchem\".\n",
    "\n",
    "Powinno udać się Państwu wyciągnąć przynajmniej `0.94` accuracy na walidacji krzyżowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.7536449349747158e-05, 244.69193226422038, 0.9841269841269841)\n",
      "(2.382369667501818e-07, 22026.465794806718, 0.9153439153439153)\n",
      "(2.7536449349747158e-05, 244.69193226422038, 0.9581151832460733)\n",
      "Srednia acuracy na teście: 0.9525286942389909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "\n",
    "gamma=np.exp(np.linspace(1,20,5)) \n",
    "gamma2=np.exp(-np.linspace(1,20,5)) \n",
    "gamma=np.concatenate((gamma,gamma2))\n",
    "C=np.exp(-np.linspace(1,10,5)) \n",
    "C2=np.exp(np.linspace(1,10,5)) \n",
    "C=np.concatenate((C,C2))\n",
    "#print(gamma,\"\\n\",C)\n",
    "datas=cross_validation(X,y,3)\n",
    "best,mean=[],[]\n",
    "for X_train,y_train,X_test,y_test in datas:\n",
    "    best_parameters=(1,1,0) # gamma, C ,accuracy\n",
    "    for g in gamma:\n",
    "        for c in C:\n",
    "            svm=SVC(gamma=g,C=c)\n",
    "            svm.fit(X_train,y_train)\n",
    "            score=svm.score(X_test,y_test)\n",
    "            if score > best_parameters[2] : best_parameters=(g,c,score)      \n",
    "    print(best_parameters)\n",
    "    best.append(best_parameters)\n",
    "    mean.append(best_parameters[2])\n",
    "        #print(g,c,accuracy(X,y,5,gamma=g,C=c))\n",
    "print(\"Srednia acuracy na teście:\",np.mean(np.array(mean)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9508660464412676\n"
     ]
    }
   ],
   "source": [
    "best_gamma=2.382369667501818e-07\n",
    "best_C= 22026.465794806718\n",
    "test=accuracy(X,y,5,gamma=best_gamma,C=best_C)\n",
    "print(test)\n",
    "assert test >= 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4. (3 punkty)\n",
    "\n",
    "Załóżmy, że naszym problemem jest zdecydowanie, która rodzina modeli *SVM* najlepiej radzi sobei z naszym datasetem. Przez rodzinę rozumiemy tutaj modele SVM z różną *funkcją bazwoą* (zwaną często *funkcją jądra*). W pakiecie mamy dostępne kilka możliwości, włącznie z podawaniem swoich własnych, ale w tym zadaniu skupimy się na czterech dostępnych od ręki: `linear`, `poly`, `rbf`, `sigmoid`.\n",
    "\n",
    "Wiemy jak znaleźć najlepszy zestaw parametrów dla danej rodziny modeli, zrobiliśmy to do tej pory dla domyślnej funkcji bazowej czyli `rbf`. Jak jednak mamy \"uczciwie\" porównać wyniki modeli pomiędzy sobą? Do tej pory patrzyliśmy na wyniki modelu dla datasetu testowego i to na podstawie tego wyniku wybieraliśmy najlepsze hiperparametry. Jakie mogą być z tym problemy? Overfitting?\n",
    "\n",
    "Rozwiązanie: jeszcze jedna walidacja krzyżowa!\n",
    "\n",
    "1. Pierwsza walidacja krzyżowa podzieli nam nasz zbiór na treningowy i testowy. Te testowe zbiory będą naszymi ostatecznymi zbiorami testowymi, na których nie będziemy w żaden sposób się uczyć czy szukać hiperparametrów. \n",
    "2. Następnie nasz zbiór treningowy podzielimy ponownie walidacją krzyżową na dwie części: faktyczny treningowy i walidacyjny. Tych dwóch podziałów będziemy używać jak poprzednio do uczenia modelu i testowania hiperparametrów.\n",
    "3. Po znalezieniu najlepszego zestawu hiperparametrów nauczymy ostatecznie nasz model na sumie zbiorów treningowego i walidacyjnego i sprawdzimy jego dokładność na ostatecznym zbiorze testowym.\n",
    "\n",
    "\n",
    "**Uwaga**: parametr `C` używany jest dla każdej możliwej funkcji bazowej. Proszę sprawdzić jakie parametry są używane dla jakich funkcji jądra. \n",
    "**Hint**: parametry, które mogą państwa interesować to oczywiście `kernel`, oraz `C`, `degree`, `gamma`, `coef0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wyliczone parametry: (100, 0.9841269841269841)\n",
      "wyliczone parametry: (100, 0.9920634920634921)\n",
      "wyliczone parametry: (0.1, 0.9444444444444444)\n",
      "Dla modelu linear najlepszy wynik to 0.9437103520873155\n",
      "wyliczone parametry: (0.1, 1, 0.01, 0.001, 0.9841269841269841)\n",
      "wyliczone parametry: (0.1, 1, 0.1, 0.001, 0.9841269841269841)\n",
      "wyliczone parametry: (100, 1, 0.1, 0.001, 0.9761904761904762)\n",
      "Dla modelu poly najlepszy wynik to 0.9349104776678946\n",
      "wyliczone parametry: (1, 0.0001, 0.9841269841269841)\n",
      "wyliczone parametry: (10, 0.0001, 0.9603174603174603)\n",
      "wyliczone parametry: (1, 0.0001, 0.9365079365079365)\n",
      "Dla modelu rbf najlepszy wynik to 0.9366002751692105\n",
      "wyliczone parametry: (0.1, 10, 0.6746031746031746)\n",
      "wyliczone parametry: (0.1, 10, 0.7109375)\n",
      "wyliczone parametry: (0.1, 10, 0.6349206349206349)\n",
      "Dla modelu sigmoid najlepszy wynik to 0.6272842276332677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "C= [0.1, 1, 10, 100]\n",
    "gamma=[0.1, 0.01, 0.0001] # dla gamma=0.001 bardzo muli\n",
    "degree= [1,10]\n",
    "coef0=[0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "datas=cross_validation(X,y,3)\n",
    "#linear C \n",
    "wyniki=[]\n",
    "for X_train,y_train,X_test,y_test in datas:\n",
    "    #print(\"for X_train\")\n",
    "    splited=cross_validation(X_train,y_train,3)\n",
    "    best_parameters=(1,0) #  C ,accuracy    \n",
    "    for xt,yt,xv,yv in splited:  # x_train, y_train, x_validation, y_validation   \n",
    "        #print(\"for xt\")\n",
    "        for c in C:\n",
    "            #print(\"for c\",c)\n",
    "            svm=SVC(kernel='linear',C=c)\n",
    "            svm.fit(xt,yt)\n",
    "            score=svm.score(xv,yv)\n",
    "            if score > best_parameters[-1] : best_parameters=(c,score)      \n",
    "        #print(\"lokal\",best_parameters)\n",
    "    #print(best_parameters) #najlepsze parametry \n",
    "    c=best_parameters[0]\n",
    "    svm=SVC(kernel='linear',C=c)\n",
    "    svm.fit(X_train,y_train)\n",
    "    wyniki.append(svm.score(X_test,y_test))\n",
    "    print(\"wyliczone parametry:\",best_parameters)\n",
    "print(\"Dla modelu linear najlepszy wynik to\",np.mean(np.array(wyniki)))\n",
    "\n",
    "#poly C deegree coef0  # chodzi tak z ponad pół godziny\n",
    "wyniki=[]\n",
    "grid = {'c': C , 'd': degree, 'g': gamma,'f':coef0}\n",
    "for X_train,y_train,X_test,y_test in datas:\n",
    "    #print(\"for X_train\")\n",
    "    splited=cross_validation(X_train,y_train,3)\n",
    "    best_parameters=(1,1,1,0) #  C ,degree,coef0,accuracy    \n",
    "    for xt,yt,xv,yv in splited:  # x_train, y_train, x_validation, y_validation   \n",
    "        #print(\"for xt\")\n",
    "        for zb in (ParameterGrid(grid)):\n",
    "            #print(zb)\n",
    "            c,d,g,f=zb['c'],zb['d'],zb['g'],zb['f']\n",
    "            #print(\"for c\",c)\n",
    "            svm=SVC(kernel='poly',C=c,degree=d,gamma=g,coef0=f)\n",
    "            #print(\"fituje\")\n",
    "            svm.fit(xt,yt)\n",
    "            #print(\"zafitowałem\")\n",
    "            score=svm.score(xv,yv)\n",
    "            if score > best_parameters[-1] : best_parameters=(c,d,g,f,score)      \n",
    "        #print(\"lokal\",best_parameters)\n",
    "    #print(best_parameters) #najlepsze parametry \n",
    "    c,d,g,f=best_parameters[0],best_parameters[1],best_parameters[2],best_parameters[3]\n",
    "    svm=SVC(kernel='poly',C=c,degree=d,gamma=g,coef0=f)\n",
    "    svm.fit(X_train,y_train)\n",
    "    wyniki.append(svm.score(X_test,y_test))\n",
    "    print(\"wyliczone parametry:\",best_parameters)\n",
    "print(\"Dla modelu poly najlepszy wynik to\",np.mean(np.array(wyniki)))\n",
    "\n",
    "#rbf C gamma \n",
    "wyniki=[]\n",
    "grid = {'c': C, 'g': gamma}\n",
    "for X_train,y_train,X_test,y_test in datas:\n",
    "    #print(\"for X_train\")\n",
    "    splited=cross_validation(X_train,y_train,3)\n",
    "    best_parameters=(1,1,1,0) #  C ,degree,coef0,accuracy    \n",
    "    for xt,yt,xv,yv in splited:  # x_train, y_train, x_validation, y_validation   \n",
    "        #print(\"for xt\")\n",
    "        for zb in (ParameterGrid(grid)):\n",
    "            #print(zb)\n",
    "            c,g=zb['c'],zb['g']\n",
    "            #print(\"for c\",c)\n",
    "            svm=SVC(kernel='rbf',C=c,gamma=g)\n",
    "            #print(\"fituje\")\n",
    "            svm.fit(xt,yt)\n",
    "            #print(\"zafitowałem\")\n",
    "            score=svm.score(xv,yv)\n",
    "            if score > best_parameters[-1] : best_parameters=(c,g,score)      \n",
    "        #print(\"lokal\",best_parameters)\n",
    "    #print(best_parameters) #najlepsze parametry \n",
    "    c,g=best_parameters[0],best_parameters[1]\n",
    "    svm=SVC(kernel='rbf',C=c,gamma=g)\n",
    "    svm.fit(X_train,y_train)\n",
    "    wyniki.append(svm.score(X_test,y_test))\n",
    "    print(\"wyliczone parametry:\",best_parameters)\n",
    "print(\"Dla modelu rbf najlepszy wynik to\",np.mean(np.array(wyniki)))\n",
    "\n",
    "#sigmoid C gamma coef0\n",
    "gamma=[10,1,0.1, 0.01, 0.0001,0.00001] # ustalam więszky zakres bo jest szybko a dla sigmoidu nie chce wyjść\n",
    "coef0=[0.001,0.01,0.1,1,10,100]\n",
    "C= [0.1, 1, 10, 100,1000]\n",
    "wyniki=[]\n",
    "grid = {'c': C, 'g': gamma, 'f': coef0}\n",
    "for X_train,y_train,X_test,y_test in datas:\n",
    "    #print(\"for X_train\")\n",
    "    splited=cross_validation(X_train,y_train,3)\n",
    "    best_parameters=(1,1,1,0) #  C ,degree,coef0,accuracy    \n",
    "    for xt,yt,xv,yv in splited:  # x_train, y_train, x_validation, y_validation   \n",
    "        #print(\"for xt\")\n",
    "        for zb in (ParameterGrid(grid)):\n",
    "            #print(zb)\n",
    "            c,g,f=zb['c'],zb['g'],zb['f']\n",
    "            #print(\"for c\",c)\n",
    "            svm=SVC(kernel='sigmoid',C=c,gamma=g,coef0=f)\n",
    "            #print(\"fituje\")\n",
    "            svm.fit(xt,yt)\n",
    "            #print(\"zafitowałem\")\n",
    "            score=svm.score(xv,yv)\n",
    "            if score > best_parameters[-1] : best_parameters=(c,g,score)      \n",
    "        #print(\"lokal\",best_parameters)\n",
    "    #print(best_parameters) #najlepsze parametry \n",
    "    c,g=best_parameters[0],best_parameters[1]\n",
    "    svm=SVC(kernel='sigmoid',C=c,gamma=g,coef0=f)\n",
    "    svm.fit(X_train,y_train)\n",
    "    wyniki.append(svm.score(X_test,y_test))\n",
    "    print(\"wyliczone parametry:\",best_parameters)\n",
    "print(\"Dla modelu sigmoid najlepszy wynik to\",np.mean(np.array(wyniki)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
